{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da334ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "# Extract mentioned users from tweet text\n",
    "def extract_mentioned_users(tweet_text):\n",
    "    return re.findall(r'@(\\w+)', tweet_text)\n",
    "\n",
    "# Extract hashtags from tweet text\n",
    "def extract_hashtags(tweet_text):\n",
    "    return re.findall(r'#(\\w+)', tweet_text)\n",
    "\n",
    "# Read and process the tweet data\n",
    "mentioned_counts = defaultdict(lambda: defaultdict(int))\n",
    "topic_counts = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))\n",
    "unique_users = defaultdict(set)  # Keep track of unique users for each day\n",
    "with open('tweets2009-07.txt', 'r', encoding='utf-8') as file:\n",
    "    file.readline()  # Skip the header line\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        \n",
    "        timestamp = datetime.datetime.strptime(line[2:], '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        line = file.readline().strip()\n",
    "        username = line[2:].split('/')[-1]\n",
    "\n",
    "        line = file.readline().strip()\n",
    "        tweet_text = line[2:]\n",
    "        \n",
    "        mentioned_users = extract_mentioned_users(tweet_text)\n",
    "        hashtags = extract_hashtags(tweet_text)\n",
    "\n",
    "        if timestamp < datetime.datetime(2009, 7, 1, 0, 0, 0) or timestamp > datetime.datetime(2009, 7, 5, 23, 59, 59):\n",
    "            continue\n",
    "\n",
    "        date = timestamp.date()\n",
    "        unique_users[date].add(username)  # Add user to the set for the specific day\n",
    "\n",
    "        for mentioned_user in mentioned_users:\n",
    "            mentioned_counts[date][(mentioned_user, username)] += 1\n",
    "        \n",
    "        for hashtag in hashtags:\n",
    "            topic_counts[date][username][hashtag] += 1\n",
    "\n",
    "# Write the mentioned counts to CSV files\n",
    "for date, data in mentioned_counts.items():\n",
    "    mentioned_csv_file = f'{date:%Y.%m.%d}_mentioned.csv'\n",
    "    with open(mentioned_csv_file, 'w', encoding='utf-8') as file:\n",
    "        file.write('from,to,weight\\n')\n",
    "        for (mentioned_user, user_from), weight in data.items():\n",
    "            file.write(f'{user_from},{mentioned_user},{weight}\\n')\n",
    "\n",
    "# Write the top topics for each user to separate CSV files for each date\n",
    "for date, user_topics in topic_counts.items():\n",
    "    topic_csv_file = f'{date:%Y.%m.%d}_topic_of_interest.csv'\n",
    "    with open(topic_csv_file, 'w', encoding='utf-8') as file:\n",
    "        file.write('user,topic_of_interest\\n')\n",
    "        for username in unique_users[date]:  # Iterate through all unique users for the specific day\n",
    "            topics = user_topics[username]\n",
    "            if topics:\n",
    "                max_count = max(topics.values())\n",
    "                top_topics = [topic for topic, count in topics.items() if count == max_count]\n",
    "                selected_topic = random.choice(top_topics)\n",
    "                file.write(f'{username},#{selected_topic}\\n')\n",
    "            else:\n",
    "                file.write(f'{username},\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18df047b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
